---
layout: post
title: "使用DataX3.0进行数据同步教程"
date: 2019-04-03
excerpt: "十六说：这是一篇关于异构数据同步工具DataX的使用手册的抄录笔记，并附上了个人采坑集锦。"
project: true
tag:
- DataX
feature: "https://user-images.githubusercontent.com/45778381/55421187-45c7c780-55ab-11e9-922d-ce698c67094c.png"
comments: true
---
# 1.DataX3.0概览

&emsp;DataX是一个异构数据源离线同步工具，致力于实现包括关系型数据库（MySQL、Oracle等）、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。

![Snipaste_2019-04-03_23-23-11](https://user-images.githubusercontent.com/45778381/55501091-3fede700-567c-11e9-9c1d-7060809d727e.png)

* 设计理念：为了解决异构数据同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。

* Github主页地址：https://github.com/alibaba/DataX

# 2.DataX3.0框架设计

![Snipaste_2019-04-03_23-30-39](https://user-images.githubusercontent.com/45778381/55501135-53994d80-567c-11e9-8ab3-bf5468d77898.png)

&emsp; DataX本身作为离线数据同步框架，采用Framework + plugin架构构建。将数据源读取和写入抽象成Reader/Writer插件，纳入到整个同步框架中。

* Reader：Reader为数据采集模块，负责采集数据源的数据，将数据发送给Framework。
* Write：Writer为数据写入模块，负责不断向Framework取数据，并将数据写入到目的端。
* Framework：Framework用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。

# 3.DataX3.0插件体系

&emsp;DataX目前支持数据如下：

| 类型 | 数据源 | Reader | Writer | 传送 |
| :-: | :-: | :-: | :-: | :--: |
| RDBMS关系型数据库 | mysql | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/mysqlreader/doc/mysqlreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/mysqlwriter/doc/mysqlwriter.md"><b>写</b></a> |
|  | Oracle | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/oraclereader/doc/oraclereader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/oraclewriter/doc/oraclewriter.md"><b>写</b></a> |
|  | SQLServer | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/sqlserverreader/doc/sqlserverreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/sqlserverwriter/doc/sqlserverwriter.md"><b>写</b></a> |
|  | PostgreSQL | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/postgresqlreader/doc/postgresqlreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/postgresqlwriter/doc/postgresqlwriter.md"><b>写</b></a> |
|  | DRDS | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/drdsreader/doc/drdsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/drdswriter/doc/drdswriter.md"><b>写</b></a> |
|  | 通用RDBMS（支持所有关系型数据库） | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/rdbmsreader/doc/rdbmsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/rdbmswriter/doc/rdbmswriter.md"><b>写</b></a> |
| 阿里云数仓数据存储 | ODPS | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/odpsreader/doc/odpsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/odpswriter/doc/odpswriter.md"><b>写</b></a> |
|  | ADS |  | √ | <a href="https://github.com/alibaba/DataX/blob/master/adswriter/doc/adswriter.md"><b>写</b></a> |
|  | OSS | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/ossreader/doc/ossreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/osswriter/doc/osswriter.md"><b>写</b></a> |
|  | OCS | √ | √ | <b>读</b>、<a href="https://github.com/alibaba/DataX/blob/master/ocswriter/doc/ocswriter.md"><b>写</b></a> |
| NoSQL数据存储 | OTS | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/otsreader/doc/otsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/otswriter/doc/otswriter.md"><b>写</b></a> |
|  | Hbase0.94 | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/hbase094xreader/doc/hbase094xreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/hbase094xwriter/doc/hbase094xwriter.md"><b>写</b></a> |
|  | Hbase1.1 | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/hbase11xsqlreader/doc/hbase11xsqlreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/hbase11xwriter/doc/hbase11xwriter.md"><b>写</b></a> |
|  | MongoDB | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/mongodbreader/doc/mongodbreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/mongodbwriter/doc/mongodbwriter.md"><b>写</b></a> |
|  | Hive | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md"><b>写</b></a> |
| 无结构化数据 | TxtFile | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/txtfilereader/doc/txtfilereader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/txtfilewriter/doc/txtfilewriter.md"><b>写</b></a> |
|  | FTP | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/ftpreader/doc/ftpreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/ftpwriter/doc/ftpwriter.md"><b>写</b></a> |
|  | HDFS | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md"><b>写</b></a> |
|  | Elasticsearch |  | √ | <a href="https://github.com/alibaba/DataX/blob/master/elasticsearchwriter/doc/elasticsearchwriter.md"><b>写</b></a> |

# 4.DataX3.0核心架构

&emsp;DataX3.0开源版本支持单机多线程模式完成同步作业运行，通过DataX作业生命周期的时序图，从整体架构设计非常简要说明DataX各个模块相互关系。

![Snipaste_2019-04-03_23-52-47](https://user-images.githubusercontent.com/45778381/55501159-6449c380-567c-11e9-8674-bf9d4f2840bf.png)

&emsp;**核心模块介绍：**

* DataX完成单个数据同步的作业，我们称之为Job，DataX接收到一个Job之后，将启动一个进程来完成整个作业同步过程。DataX Job模块是单个作业的中枢管理节点，承担了数据清洗，子任务切分（将单一作业计算做换化为多个子Task）、TaskGroup管理等功能。
* DataXJob启动后，会根据不同的源端切分策略，将Job切分成多个小的Task（子任务），以便于并发执行。Task便是DataX作业的最小单元，每一个Task都会负责一部分数据的同步工作。
* 切分多个Task之后，DataX Job会调用Scheduler模块，根据配置的并发数据量，将拆分成的Task重新组合，组装成TaskGroup（任务组）。每一个TaskGroup负责以一定的并发运行完毕分配好的所有Task，默认单个任务组的并发数量为5.
* 每一个Task都由TaskGroup负责启动，Task启动后，会固定启动Reader——>Channel——>Write的线程来完成任务同步工作。
* DataX作业运行起来之后，Job监控并等待多个TaskGroup模块任务完成，等待所有TaskGroup任务完成后Job成功退出，否则，异常退出，进程退出值非0。

&emsp;**DataX调度流程：**

&emsp;例如：用户提交了一个DataX作业，并且配置了20个并发，目的是将一个100张分表的mysql数据同步到odps里面。DataX的调度决策思路是：

* DataXJob根据分库分表切分成了100个Task。
* 根据20个并发，DataX计算共需要分配4个TaskGroup。
* 4个TaskGroup平分切分好的100个Task，每个TaskGroup负责5个并发共计运行25个Task。

# 5.DataX3.0六大核心优势

* 可靠的数据质量监控：完美解决数据传输个别类型失真问题，提供作业全链路的流量、数据量运行时监控，**提供脏数据探测**。
* 丰富的数据转换功能：ETL、转换、脱敏、补全、过滤。
* 精准的速度控制：

```
"speed": {
    "channel": 5,
    "byte": 1048576,
    "record": 10000
}
```

* 强劲同步性能：每一个读插件都有切分策略。
* 健壮的容错机制：线程内部重试，线程级别重试。
* 极简的使用体验：易用，详细。

# 6.快速部署
* <a href="http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz"><b>十六的传送门：DataX下载地址</b></a>
* 前提是Linux环境下
* <a href="http://www.oracle.com/technetwork/cn/java/javase/downloads/index.html"><b>安装JDK（1.8以上，推荐1.8）配置环境变量</b></a>
* <a href="https://www.python.org/downloads/"><b>安装Python（推荐Python2.6.X）配置环境变</b></a>
* <a href="https://maven.apache.org/download.cgi"><b>安装Maven 3.X（编译时要用） 配置环境变</b></a>
* 进入到安装目录解压：`tar -zxvf DataX.tar.gz -C "你想放的目录"`
* 进入DataX的bin目录：`cd /"你想放的目录"/DataX/bin`
* 执行自检脚本确保安装成功：`python datax.py ../job/job.json` 
* 进入`DataX/job`中编写自己的`.json`文件，模板在表格后面的**读、写**传送连接中。
* 执行命令：`python datax.py ../job/"your_job.json"`
* 例如：从ODPS到MySQL的脚本模板，其中有些是必须字段，有些是可选字段。

```
-- ODPS2MySQL
-- ODPSReader不是通过ODPS SQL（select...from...where...）来抽取数据的。
-- 读取分区表时，需要指定出具体的分区配置。表字段可以依序指定全部列，也可指定部分列，或调整顺序，或指定常量字段，但是表字段中不能指定分区列（分区字段不是表字段） 
-- jdbcUrl按照Musql官方规范，并可以填写连接附加控制信息，比如想指定连接编码为jdk，则在jdbcUrl后面追加属性  useUnicode=true&characterEncoding=gbk。  
{
    "job": {
        "setting": {
            "speed": {
                "channel": 1
            }
        },
        "content": [
            {
                "reader": {
                    "name": "odpsreader",
                    "parameter": {
                        "accessId": "",
                        "accessKey": "",
                        "project": "",
                        "table": "",
                        "//": "分区，一定要写到最后一层分区",
                        "partition": [
                            "pt= , ds= "
                        ],
                        "//": "字段",
                        "column": [
                            "","","",""
                        ],
                        "//": "被package授权的project，即用户当前所在project",
                        "packageAuthorizedProject": "",
                        "//": "切分模式，默认为record，可以指定位partition",
                        "splitMode": "",
                        "//": "ODPS的tunnelserver地址，线上地址为 http://dt.odps.aliyun.com",
                        "tunnelServer": "",
                        "//": "ODPS的server地址，线上地址为 http://service.odps.aliyun.com/api",
                        "odpsServer": "",
                        "//": "是否压缩（true或者false）",
                        "isCompress": ""
                    }
                },
                "writer": {
                    "name": "mysqlwriter",
                    "parameter": {
                        "//": "写入数据到目标表采用 insert into 或者 replace into 或者 on duplicate key update 语句 （追加、替换、更新）",
                        "writeMode": "insert",
                        "//": "一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐。",
                        "batchSize": "",
                        "username": "root",
                        "password": "root",
                        "//": "字段,可以用 * 代替，但是不建议",
                        "column": [
                            "","",""
                        ],
                        "//": "DataX载获取Mysql链接时，执行session指定的SQL语句，修改当前connection session",
                        "session": [
                            ""
                        ],
                        "//": "写入数据到目的表之前会先执行这里的标准语句",
                        "preSql": [
                            ""
                        ],
                        "//": "写入数据到目的表之后会先执行这里的标准语句",
                        "postSql": [
                            ""
                        ],
                        "connection": [
                            {
                                "jdbcUrl": "",
                                "table": [
                                    ""
                                ]
                            }
                        ]
                    }
                }
            }
        ]
    }
}
```

* 例如：从MySQL到ODPS的脚本模板，其中有些是必须字段，有些是可选字段。

```
-- MySQL2ODPS
-- MysqlReader插件实现了从MySQL读取数据。在底层实现上，MysqlReader通过JDBC连接远程MySQL数据库，并执行相应的SQL语句将数据从Mysql库中select出来。
-- 如果是分区表，必须要写分区信息，如果有多级分区，要写到最后一级分区。
-- 设置为true，保证写入的幂等性，即当出现写入失败再次运行时，ODPSWrite将清理前述数据，并导入新数据，这样可以保证每次重跑之后数据都一致。
-- 这并不是原子操作，DOPS SQl无法做到原子性。多任务操作同一个Table/Partition清理分区时，可能出现并发时序问题。建议不要多个作业同时操作一份分区。
{
    "job": {
        "setting": {
            "speed": {
                "channel": 1
            }
        },
        "content": [
            {
                "reader": {
                    "name": "mysqlwriter",
                    "parameter": {
                        "username": "",
                        "password": "",
                        "//": "字段,可以用 * 表示所有字段，但不建议",
                        "column": [
                            "","",""
                        ],
                        "//": "表示用户希望用splitPK代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大体用数据同步效能。通常推荐使用表主键，因为主键分布比较均匀，不会出现数据热点问题。",
                        "splitPk": "",
                        "//": "筛选条件：MysqlReader根据指定的column、table、where条件拼接成SQL，并根据这个SQL进行数据抽取。",
                        "//": "where可以有效的实现数据增量和数据全量的同步",
                        "where": "",
                        "//": "某些业务下，where配置不足以描述所有筛选条件，用户可以通过该配置型来自定义筛选SQL。当配置了这一项之后，DataX系统就会忽略table，column这些配置型。直接使用这个配置项的内容对数据进行筛选。",
                        "connection": [
                            {
                                "querySql": [
                                    ""
                                ],
                                "jdbcUrl": [
                                    ""
                                ],
                                "table": [
                                    ""
                                ]
                            }
                        ]
                    }
                },
                "writer": {
                    "name": "odpsWirter",
                    "parameter": {
                        "project": "",
                        "table": "",
                        "//": "如果是分区表，必须要写分区信息，如果有多级分区，要写到最后一级分区。",
                        "partition": "",
                        "//": "字段,可以用 * 表示所有字段，但不建议",
                        "column": [
                            "","",""
                        ],
                        "accessId": "",
                        "accessKey": "",
                        "//": "设置为true，保证写入的幂等性，即当出现写入失败再次运行时，ODPSWrite将清理前述数据，并导入新数据，这样可以保证每次重跑之后数据都一致。",
                        "//": "这并不是原子操作，DOPS SQl无法做到原子性。多任务操作同一个Table/Partition清理分区时，可能出现并发时序问题。建议不要多个作业同时操作一份分区。",
                        "truncate": "true",
                        "//": "ODPS的server地址，线上地址为 http://service.odps.aliyun.com/api",
                        "odpsServer": "",
                        "//": "ODPS的tunnelserver地址，线上地址为 http://dt.odps.aliyun.com",
                        "tunnelServer": ""
                    }
                }
            }
        ]
    }
}
```

# 7.踩坑集锦

* mysqlreader中的jdbcUrl需要`[]`括起来，而mysqlWriter中是不需要的。否则会报如下错误：

```
com.alibaba.datax.common.exception.DataXException: Code:[Framework-02], Description:[DataX引擎运行过程出错，具体原因请参看DataX运行结束时的错误诊断信息  .].  - java.lang.ClassCastException: java.lang.String cannot be cast to java.util.List
	at com.alibaba.datax.common.util.Configuration.getList(Configuration.java:426)
	at com.alibaba.datax.plugin.rdbms.reader.util.OriginalConfPretreatmentUtil.dealJdbcAndTable(OriginalConfPretreatmentUtil.java:84)
	at com.alibaba.datax.plugin.rdbms.reader.util.OriginalConfPretreatmentUtil.simplifyConf(OriginalConfPretreatmentUtil.java:59)
	at com.alibaba.datax.plugin.rdbms.reader.util.OriginalConfPretreatmentUtil.doPretreatment(OriginalConfPretreatmentUtil.java:33)
	at com.alibaba.datax.plugin.rdbms.reader.CommonRdbmsReader$Job.init(CommonRdbmsReader.java:55)
	at com.alibaba.datax.plugin.reader.mysqlreader.MysqlReader$Job.init(MysqlReader.java:37)
	at com.alibaba.datax.core.job.JobContainer.initJobReader(JobContainer.java:673)
	at com.alibaba.datax.core.job.JobContainer.init(JobContainer.java:303)
	at com.alibaba.datax.core.job.JobContainer.start(JobContainer.java:113)
	at com.alibaba.datax.core.Engine.start(Engine.java:92)
	at com.alibaba.datax.core.Engine.entry(Engine.java:171)
	at com.alibaba.datax.core.Engine.main(Engine.java:204)
```

* DataX不能用于连接同步Windows下的MySQL数据库，会报无法连接错误。

# 8.更多详情

<center><a href="https://github.com/alibaba/DataX"><b>十六的传送门</b></a></center>
