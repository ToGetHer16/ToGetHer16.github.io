---
layout: post
title: "使用DataX3.0进行数据同步教程"
date: 2019-04-03
excerpt: "十六说：这是一篇关于异构数据同步工具DataX的使用手册的抄录笔记，并附上了个人采坑集锦。"
project: true
tag:
- DataX
feature: "https://user-images.githubusercontent.com/45778381/55421187-45c7c780-55ab-11e9-922d-ce698c67094c.png"
comments: true
---
# 1.DataX3.0概览

&emsp;DataX是一个异构数据源离线同步工具，致力于实现包括关系型数据库（MySQL、Oracle等）、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。

![Snipaste_2019-04-03_23-23-11](https://user-images.githubusercontent.com/45778381/55501091-3fede700-567c-11e9-9c1d-7060809d727e.png)

* 设计理念：为了解决异构数据同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。

* Github主页地址：https://github.com/alibaba/DataX

# 2.DataX3.0框架设计

![Snipaste_2019-04-03_23-30-39](https://user-images.githubusercontent.com/45778381/55501135-53994d80-567c-11e9-8ab3-bf5468d77898.png)

&emsp; DataX本身作为离线数据同步框架，采用Framework + plugin架构构建。将数据源读取和写入抽象成Reader/Writer插件，纳入到整个同步框架中。

* Reader：Reader为数据采集模块，负责采集数据源的数据，将数据发送给Framework。
* Write：Writer为数据写入模块，负责不断向Framework取数据，并将数据写入到目的端。
* Framework：Framework用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。

# 3.DataX3.0插件体系

&emsp;DataX目前支持数据如下：

| 类型 | 数据源 | Reader | Writer | 传送 |
| :-: | :-: | :-: | :-: | :--: |
| RDBMS关系型数据库 | mysql | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/mysqlreader/doc/mysqlreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/mysqlwriter/doc/mysqlwriter.md"><b>写</b></a> |
|  | Oracle | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/oraclereader/doc/oraclereader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/oraclewriter/doc/oraclewriter.md"><b>写</b></a> |
|  | SQLServer | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/sqlserverreader/doc/sqlserverreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/sqlserverwriter/doc/sqlserverwriter.md"><b>写</b></a> |
|  | PostgreSQL | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/postgresqlreader/doc/postgresqlreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/postgresqlwriter/doc/postgresqlwriter.md"><b>写</b></a> |
|  | DRDS | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/drdsreader/doc/drdsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/drdswriter/doc/drdswriter.md"><b>写</b></a> |
|  | 通用RDBMS（支持所有关系型数据库） | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/rdbmsreader/doc/rdbmsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/rdbmswriter/doc/rdbmswriter.md"><b>写</b></a> |
| 阿里云数仓数据存储 | ODPS | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/odpsreader/doc/odpsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/odpswriter/doc/odpswriter.md"><b>写</b></a> |
|  | ADS |  | √ | <a href="https://github.com/alibaba/DataX/blob/master/adswriter/doc/adswriter.md"><b>写</b></a> |
|  | OSS | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/ossreader/doc/ossreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/osswriter/doc/osswriter.md"><b>写</b></a> |
|  | OCS | √ | √ | <b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/ocswriter/doc/ocswriter.md"><b>写</b></a> |
| NoSQL数据存储 | OTS | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/otsreader/doc/otsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/otswriter/doc/otswriter.md"><b>写</b></a> |
|  | Hbase0.94 | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/hbase094xreader/doc/hbase094xreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/hbase094xwriter/doc/hbase094xwriter.md"<b>写</b></a> |
|  | Hbase1.1 | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/hbase11xsqlreader/doc/hbase11xsqlreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/hbase11xwriter/doc/hbase11xwriter.md"><b>写</b></a> |
|  | MongoDB | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/mongodbreader/doc/mongodbreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/mongodbwriter/doc/mongodbwriter.md"><b>写</b></a> |
|  | Hive | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md"><b>写</b></a> |
| 无结构化数据 | TxtFile | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/txtfilereader/doc/txtfilereader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/txtfilewriter/doc/txtfilewriter.md"><b>写</b></a> |
|  | FTP | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/ftpreader/doc/ftpreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/ftpwriter/doc/ftpwriter.md"><b>写</b></a> |
|  | HDFS | √ | √ | <a href="https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md"><b>读</b></a>、<a href="https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md"><b>写</b></a> |
|  | Elasticsearch |  | √ | <a href="https://github.com/alibaba/DataX/blob/master/elasticsearchwriter/doc/elasticsearchwriter.md"><b>写</b></a> |

# 4.DataX3.0核心架构

&emsp;DataX3.0开源版本支持单机多线程模式完成同步作业运行，通过DataX作业生命周期的时序图，从整体架构设计非常简要说明DataX各个模块相互关系。

![Snipaste_2019-04-03_23-52-47](https://user-images.githubusercontent.com/45778381/55501159-6449c380-567c-11e9-8674-bf9d4f2840bf.png)

&emsp;**核心模块介绍：**

* DataX完成单个数据同步的作业，我们称之为Job，DataX接收到一个Job之后，将启动一个进程来完成整个作业同步过程。DataX Job模块是单个作业的中枢管理节点，承担了数据清洗，子任务切分（将单一作业计算做换化为多个子Task）、TaskGroup管理等功能。
* DataXJob启动后，会根据不同的源端切分策略，将Job切分成多个小的Task（子任务），以便于并发执行。Task便是DataX作业的最小单元，每一个Task都会负责一部分数据的同步工作。
* 切分多个Task之后，DataX Job会调用Scheduler模块，根据配置的并发数据量，将拆分成的Task重新组合，组装成TaskGroup（任务组）。每一个TaskGroup负责以一定的并发运行完毕分配好的所有Task，默认单个任务组的并发数量为5.
* 每一个Task都由TaskGroup负责启动，Task启动后，会固定启动Reader——>Channel——>Write的线程来完成任务同步工作。
* DataX作业运行起来之后，Job监控并等待多个TaskGroup模块任务完成，等待所有TaskGroup任务完成后Job成功退出，否则，异常退出，进程退出值非0。

&emsp;**DataX调度流程：**

&emsp;例如：用户提交了一个DataX作业，并且配置了20个并发，目的是将一个100张分表的mysql数据同步到odps里面。DataX的调度决策思路是：

* DataXJob根据分库分表切分成了100个Task。
* 根据20个并发，DataX计算共需要分配4个TaskGroup。
* 4个TaskGroup平分切分好的100个Task，每个TaskGroup负责5个并发共计运行25个Task。

# 5.DataX3.0六大核心优势

* 可靠的数据质量监控：完美解决数据传输个别类型失真问题，提供作业全链路的流量、数据量运行时监控，**提供脏数据探测**。
* 丰富的数据转换功能：ETL、转换、脱敏、补全、过滤。
* 精准的速度控制：

```
"speed": {
    "channel": 5,
    "byte": 1048576,
    "record": 10000
}
```

* 强劲同步性能：每一个读插件都有切分策略。
* 健壮的容错机制：线程内部重试，线程级别重试。
* 极简的使用体验：易用，详细。

# 6.快速部署
* <a href=http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz><b>十六的传送门：DataX下载地址</b></a>
* 前提是Linux环境下
* <a href=http://www.oracle.com/technetwork/cn/java/javase/downloads/index.html><b>安装JDK（1.8以上，推荐1.8）</b></a>
* <a href=https://www.python.org/downloads/><b>安装Python（推荐1Python2.6.X）</b></a>
* <a href=https://maven.apache.org/download.cgi><b>安装Maven 3.X(编译时要用)</b></a>
* 解压：`tar -zxvf DataX.tar.gz -C "where_you_want"`
* `cd DataX/bin`
* 执行命令：`python datax.py "your_job.json"`
* 自检脚本：`python datax.py ../job/job.json` 

# 7.踩坑集锦

&emsp;

# 8.更多详情

<center><a href="https://github.com/alibaba/DataX"><b>十六的传送门</b></a></center>
